# Data Summary: River Knowledge Dataset for POC-4 Rivers Extended

The `data/` directory contains a comprehensive knowledge base of river information extracted from DBpedia, serving as the foundational dataset for the experimental evaluation of truth-constrained LLM architectures in the World Mind project. The collection comprises 9,538 unique river entities described through 21 structured attributes including geographical coordinates, hydrological metrics, ecological relationships, and toponymic details. This dataset represents a curated subset designed to test the project's core hypothesis: that architectural coupling between generative models and formal knowledge representations can systematically prevent hallucination by enforcing evidence-based licensing constraints.

The primary raw dataset (`raw_rivers.csv`, 5.3MB) contains river entities with attributes such as length, discharge, watershed areas, source and mouth locations with elevations, tributary relationships, and administrative jurisdictions. An enhanced version (`raw_rivers_filled.csv`, 6.2MB) augments these records with an additional `otherNames` column, expanding the referential surface area for evaluating temporal and geographic consistency violations. The structural richness of this data—particularly the explicit modeling of temporal extents, spatial hierarchies, and relational constraints between entities—directly supports the ontological grounding requirements outlined in the strategic framework.

Systematically derived from this knowledge base are two evaluation datasets (`river_qa_dataset.csv` and `river_qa_dataset_shuffled.csv`, both 3.6MB) containing 17,726 question-answer pairs that probe the factual boundaries of the available information. Each river is associated with multiple-choice questions testing recall of specific numerical values, geographical relationships, temporal constraints, and category classifications. The shuffled variant randomizes answer positions to prevent positional bias during model evaluation, ensuring that model performance reflects genuine semantic understanding rather than pattern recognition of answer placement.

This dataset architecture enables testing the consistency auditor and abstraction policy mechanisms by providing a structured domain where claims can be programmatically validated against formal constraints—such as temporal overlap requirements for historical relationships or spatial consistency for geographical assertions. The scale and coverage (spanning multiple countries, river systems, and temporal periods) allows for statistically robust evaluation of hallucination detection rates across diverse constraint violation patterns, directly addressing the research objective of demonstrating architectural enforcement of truth conditions.

